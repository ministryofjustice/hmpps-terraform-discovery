#!/usr/bin/env python
"""Terraform discovery - parses the cloudplatform environments repo for namespace and terraform resources, and stores the results in the service catalogue"""

import os
import threading
import re
from hmpps import ServiceCatalogue, Slack
from hmpps.services.job_log_handling import log_debug, log_error, log_info, job

# import json
from git import Repo
from tfparse import load_from_path
from time import sleep


class Services:
  def __init__(self, sc_params, slack_params):
    self.slack = Slack(slack_params)
    self.sc = ServiceCatalogue(sc_params)

    if not self.sc.connection_ok:
      self.slack.alert(
        '*Terraform Discovery failed*: Unable to connect to the Service Catalogue'
      )
      raise SystemExit()


# Set maximum number of concurrent threads to run
MAX_THREADS = 10
LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO').upper()
TEMP_DIR = os.getenv('TEMP_DIR', '/tmp/cp_envs')

# A global list of namespaces processed to avoid duplication
namespaces = []


# Process the terraform HMPPS template
def process_terraform_hmpps_template(hmpps_template):
  # Delete ID that is generated by tfparse
  del hmpps_template['id']
  # Process fields
  hmpps_template.update({'tf_label': hmpps_template['__tfmeta']['label']})
  hmpps_template.update({'tf_line_start': hmpps_template['__tfmeta']['line_start']})
  hmpps_template.update({'tf_line_end': hmpps_template['__tfmeta']['line_end']})
  hmpps_template.update({'tf_path': hmpps_template['__tfmeta']['path']})
  hmpps_template.update({'tf_filename': hmpps_template['__tfmeta']['filename']})
  hmpps_template.update({'tf_mod_version': hmpps_template.get('tf_mod_version', '')})
  hmpps_template.update({'application': hmpps_template['application']})
  hmpps_template.update(
    {
      'application_insights_instance': hmpps_template['application_insights_instance']
      if 'application_insights_instance' in hmpps_template
      else None
    }
  )
  hmpps_template.update({'environment_name': hmpps_template['environment']})
  hmpps_template.update({'github_repo': hmpps_template['github_repo']})
  hmpps_template.update(
    {
      'github_team_name': hmpps_template['github_team']
      if 'github_team' in hmpps_template
      else None
    }
  )
  hmpps_template.update({'is_production': hmpps_template['is_production']})
  hmpps_template.update({'namespace': namespace if 'namespace' in locals() else None})
  hmpps_template.update(
    {
      'reviewer_teams': hmpps_template['reviewer_teams']
      if 'reviewer_teams' in hmpps_template and hmpps_template['reviewer_teams']
      else []
    }
  )
  hmpps_template.update(
    {
      'selected_branch_patterns': hmpps_template['selected_branch_patterns']
      if 'selected_branch_patterns' in hmpps_template
      else []
    }
  )
  hmpps_template.update(
    {
      'source_template_repo': hmpps_template['source_template_repo']
      if 'source_template_repo' in hmpps_template
      else None
    }
  )
  hmpps_template.update(
    {
      'protected_branches_only': hmpps_template['protected_branches_only']
      if 'protected_branches_only' in hmpps_template
      else None
    }
  )
  hmpps_template.update(
    {
      'prevent_self_review': hmpps_template['prevent_self_review']
      if 'prevent_self_review' in hmpps_template
      else None
    }
  )

  # Clean up field not used in post to SC
  del hmpps_template['__tfmeta']

  # Check for existing template in SC and update same ID if so.
  try:
    # If there are any hmpps_templates in the existing SC data
    if sc_namespace_attributes.get('hmpps_template', {}):
      # Find the template SC ID that matches
      template_id = list(
        filter(
          lambda template: template['tf_path'] == hmpps_template['__tfmeta']['path'],
          sc_namespace_attributes.get('hmpps_terraform', {}),
        )
      )[0]['id']
      hmpps_template.update({'id': template_id})
  except (IndexError, KeyError):
    pass
  return hmpps_template


def process_repo(component, lock, services):
  global namespaces
  sc = services.sc

  for envs in component['attributes']['envs']['data']:
    environment = envs['attributes']
    namespace = environment.get('namespace', {})
    log_debug(f'Processing environment/namepace: {environment["name"]}:{namespace}')
    if namespace not in namespaces:
      # Add namespace to list of namespaces being done.
      namespaces.append(namespace)
    else:
      # Skip this namespace as it's already processed.
      log_debug(f'skipping {namespace} namespace - already been processed')
      continue

    namespace_id = None
    sc_namespace_attributes = {}
    if sc_namespace_data := sc.get_record(sc.namespaces_get, 'name', namespace):
      sc_namespace_attributes = sc_namespace_data.get('attributes', {})
      log_debug(f'Namespace data: {sc_namespace_data}')
      namespace_id = sc_namespace_data.get('id')
      log_debug(f'Namespace ID: {namespace_id}')

    # initialise the data dictionary
    data = {'name': namespace}

    resources_dir = f'{TEMP_DIR}/namespaces/live.cloud-platform.service.justice.gov.uk/{namespace}/resources'

    if os.path.isdir(resources_dir):
      # tfparse is not thread-safe!
      with lock:
        log_debug(f'Thread locked for tfparse: {resources_dir}')
        parsed = load_from_path(resources_dir)

      # loop through each module
      for module in parsed['module']:
        # Get terraform module version

        if source := module.get('source'):
          try:
            regex = r'(?<=[\\?]ref=)[0-9]+(\.[0-9])?(\.[0-9])?$'
            if tf_mod_versions := re.search(regex, source):
              module['tf_mod_version'] = tf_mod_versions[0]
          except TypeError:
            pass

          # Check if the namespace uses the cloud-platform-terraform-hmpps-template
          if 'cloud-platform-terraform-hmpps-template' in source:
            hmpps_template = process_terraform_hmpps_template(module)
            if 'hmpps_template' in data:
              data['hmpps_template'].append(hmpps_template)
            else:
              data['hmpps_template'] = []

          # Look for RDS instances.
          if 'cloud-platform-terraform-rds-instance' in source:
            rds_instance = module
            # Delete ID that is generated by tfparse
            del rds_instance['id']
            # Process fields
            rds_instance.update({'tf_label': rds_instance['__tfmeta']['label']})
            rds_instance.update({'tf_filename': rds_instance['__tfmeta']['filename']})
            rds_instance.update({'tf_path': rds_instance['__tfmeta']['path']})
            rds_instance.update({'tf_line_end': rds_instance['__tfmeta']['line_end']})

            # convert db_max_allocated_storage to string, as occasionally it is seen as a integer
            if 'db_max_allocated_storage' in rds_instance and isinstance(
              rds_instance['db_max_allocated_storage'], int
            ):
              log_debug(
                f'Converting db_max_allocated_storage to string: {rds_instance["db_max_allocated_storage"]}'
              )
              rds_instance['db_max_allocated_storage'] = str(
                rds_instance['db_max_allocated_storage']
              )

            rds_instance.update(
              {'tf_line_start': rds_instance['__tfmeta']['line_start']}
            )
            rds_instance.update({'tf_mod_version': tf_mod_version})

            # Check for existing instance in SC and update same ID if so.
            try:
              # If there are any rds instances in the existing SC data
              if sc_namespace_attributes.get('rds_instance', {}):
                # Find the RDS instance SC ID that matches
                rds_id = list(
                  filter(
                    lambda rds: rds['tf_path'] == rds_instance['__tfmeta']['path'],
                    sc_namespace_attributes.get('rds_instance', {}),
                  )
                )[0]['id']
                rds_instance.update({'id': rds_id})
            except IndexError:
              pass

            # Clean up field not used in post to SC
            del rds_instance['__tfmeta']
            data.update({'rds_instance': [rds_instance]})

          # Look for elasticache instances.
          if 'cloud-platform-terraform-elasticache-cluster' in source:
            elasticache_cluster = module
            # Delete ID that is generated by tfparse
            del elasticache_cluster['id']
            # Process fields
            elasticache_cluster.update(
              {'tf_label': elasticache_cluster['__tfmeta']['label']}
            )
            elasticache_cluster.update(
              {'tf_filename': elasticache_cluster['__tfmeta']['filename']}
            )
            elasticache_cluster.update(
              {'tf_path': elasticache_cluster['__tfmeta']['path']}
            )
            elasticache_cluster.update(
              {'tf_line_end': elasticache_cluster['__tfmeta']['line_end']}
            )
            elasticache_cluster.update(
              {'tf_line_start': elasticache_cluster['__tfmeta']['line_start']}
            )

            # if parameter_group_name refers to another tf resource, get the name of the resource.
            if 'parameter_group_name' in elasticache_cluster and isinstance(
              elasticache_cluster['parameter_group_name'], dict
            ):
              elasticache_cluster['parameter_group_name'] = elasticache_cluster[
                'parameter_group_name'
              ]['__name__']

            elasticache_cluster.update({'tf_mod_version': tf_mod_version})
            # Check for existing instance in SC and update same ID if so.
            try:
              # If there are any rds instances in the existing SC data
              if sc_namespace_attributes.get('elasticache_cluster', {}):
                # Find the elasticache cluster SC ID that matches
                elasticache_id = list(
                  filter(
                    lambda elasticache: elasticache['tf_path']
                    == elasticache_cluster['__tfmeta']['path'],
                    sc_namespace_attributes.get('elasticache_cluster', {}),
                  )
                )[0]['id']
                elasticache_cluster.update({'id': elasticache_id})
            except (IndexError, KeyError):
              pass

            # Clean up field not used in post to SC
            del elasticache_cluster['__tfmeta']
            data.update({'elasticache_cluster': [elasticache_cluster]})

          if 'pingdom_check' in parsed.keys():
            for r in parsed['pingdom_check']:
              # Look for pingdom checks.
              if 'http' in r['type'] and '__tfmeta' in r.keys():
                pingdom_check = r
                # Delete ID that is generated by tfparse
                del pingdom_check['id']
                # Process fields
                pingdom_check.update({'tf_label': pingdom_check['__tfmeta']['label']})
                pingdom_check.update(
                  {'tf_filename': pingdom_check['__tfmeta']['filename']}
                )
                pingdom_check.update({'tf_path': pingdom_check['__tfmeta']['path']})
                pingdom_check.update(
                  {'tf_line_end': pingdom_check['__tfmeta']['line_end']}
                )
                pingdom_check.update(
                  {'tf_line_start': pingdom_check['__tfmeta']['line_start']}
                )
                # pingdom_check.update({'tf_mod_version': tf_mod_version})
                # Check for existing instance in SC and update same ID if so.
                try:
                  # If there are any rds instances in the existing SC data
                  if sc_namespace_attributes.get('pingdom_check', {}):
                    # Find the Pingdom check SC ID that matches
                    pingdom_id = list(
                      filter(
                        lambda pingdom: pingdom['tf_path']
                        == pingdom_check['__tfmeta']['path'],
                        sc_namespace_attributes.get('pingdom_check', {}),
                      )
                    )[0]['id']
                    pingdom_check.update({'id': pingdom_id})
                except IndexError:
                  pass

                # Clean up field not used in post to SC
                del pingdom_check['__tfmeta']
                data.update({'pingdom_check': [pingdom_check]})

    # update or add the namespace record
    log_debug(f'Namespace id:{namespace_id}, data: {data}')
    if namespace_id:
      sc.update('namespaces', namespace_id, data)
    else:
      sc.add('namespaces', data)

  return True


def process_components(components, services):
  log_info(f'Processing batch of {len(components)} components...')
  lock = threading.Lock()
  component_count = 1
  t_repo = threading.local()
  for component in components:
    t_repo = threading.Thread(
      target=process_repo, args=(component, lock, services), daemon=True
    )

    # Apply limit on total active threads
    while threading.active_count() > (MAX_THREADS - 1):
      log_debug(f'Active Threads={threading.active_count()}, Max Threads={MAX_THREADS}')
      sleep(10)

    t_repo.start()
    component_name = component['attributes']['name']
    log_info(
      f'Started thread for {component_name} ({component_count}/{len(components)})'
    )
    component_count += 1

  t_repo.join()
  log_info('Completed processing components')


def main():
  slack_params = {
    'token': os.getenv('SLACK_BOT_TOKEN'),
    'notify_channel': os.getenv('SLACK_NOTIFY_CHANNEL', ''),
    'alert_channel': os.getenv('SLACK_ALERT_CHANNEL', ''),
  }

  # service catalogue parameters
  sc_params = {
    'url': os.getenv('SERVICE_CATALOGUE_API_ENDPOINT'),
    'key': os.getenv('SERVICE_CATALOGUE_API_KEY'),
    'filter': os.getenv('SC_FILTER', ''),
  }

  job.name = 'hmpps-terraform-discovery'
  services = Services(sc_params, slack_params)
  sc = services.sc
  slack = services.slack
  if not os.path.isdir(TEMP_DIR):
    try:
      cp_envs_repo = Repo.clone_from(
        'https://github.com/ministryofjustice/cloud-platform-environments.git', TEMP_DIR
      )
    except Exception as e:
      slack.alert(
        f'*Terraform Discovery failed*: Unable to clone cloud-platform-environments repo: {e}'
      )
      log_error(f'Unable to clone cloud-platform-environments repo: {e}')
      sc.update_scheduled_job('Failed')
      raise SystemExit()
  else:
    try:
      cp_envs_repo = Repo(TEMP_DIR)
      origin = cp_envs_repo.remotes.origin
      origin.pull()
    except Exception as e:
      slack.alert(
        f'*Terraform Discovery failed*: Unable to pull latest version of cloud-platform-environments repo: {e}'
      )
      log_error(
        f'Unable to pull latest version of cloud-platform-environments repo: {e}'
      )
      sc.update_scheduled_job('Failed')
      raise SystemExit()

  sc_data = sc.get_all_records(sc.components_get)
  if sc_data:
    process_components(sc_data, services)

  if job.error_messages:
    sc.update_scheduled_job('Errors')
    log_info('Terraform discovery job completed  with errors.')
  else:
    sc.update_scheduled_job('Succeeded')
    log_info('Terraform discovery job completed successfully.')


if __name__ == '__main__':
  main()
