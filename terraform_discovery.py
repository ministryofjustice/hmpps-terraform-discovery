#!/usr/bin/env python
"""Terraform discovery - parses the cloudplatform environments repo for namespace and terraform resources, and stores the results in the service catalogue"""

import os
import threading
import re
from hmpps import ServiceCatalogue, Slack
from hmpps.services.job_log_handling import log_debug, log_error, log_info, job

# import json
from git import Repo
from tfparse import load_from_path
from time import sleep


class Services:
  def __init__(self, sc_params, slack_params):
    self.slack = Slack(slack_params)
    self.sc = ServiceCatalogue(sc_params)

    if not self.sc.connection_ok:
      self.slack.alert(
        '*Terraform Discovery failed*: Unable to connect to the Service Catalogue'
      )
      raise SystemExit()


# Set maximum number of concurrent threads to run
MAX_THREADS = 10
LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO').upper()
TEMP_DIR = os.getenv('TEMP_DIR', '/tmp/cp_envs')

# A global list of namespaces processed to avoid duplication
namespaces = []


# Process the terraform HMPPS template
def process_terraform_hmpps_template(hmpps_template):
  # Delete ID that is generated by tfparse
  del hmpps_template['id']
  # Process fields
  hmpps_template.update({'tf_label': hmpps_template['__tfmeta']['label']})
  hmpps_template.update({'tf_line_start': hmpps_template['__tfmeta']['line_start']})
  hmpps_template.update({'tf_line_end': hmpps_template['__tfmeta']['line_end']})
  hmpps_template.update({'tf_path': hmpps_template['__tfmeta']['path']})
  hmpps_template.update({'tf_filename': hmpps_template['__tfmeta']['filename']})
  hmpps_template.update({'tf_mod_version': hmpps_template.get('tf_mod_version', '')})
  hmpps_template.update({'application': hmpps_template['application']})
  hmpps_template.update(
    {
      'application_insights_instance': hmpps_template['application_insights_instance']
      if 'application_insights_instance' in hmpps_template
      else None
    }
  )
  hmpps_template.update({'environment_name': hmpps_template['environment']})
  hmpps_template.update({'github_repo': hmpps_template['github_repo']})
  hmpps_template.update(
    {
      'github_team_name': hmpps_template['github_team']
      if 'github_team' in hmpps_template
      else None
    }
  )
  hmpps_template.update({'is_production': hmpps_template['is_production']})
  hmpps_template.update({'namespace': namespace if 'namespace' in locals() else None})
  hmpps_template.update(
    {
      'reviewer_teams': hmpps_template['reviewer_teams']
      if 'reviewer_teams' in hmpps_template and hmpps_template['reviewer_teams']
      else []
    }
  )
  hmpps_template.update(
    {
      'selected_branch_patterns': hmpps_template['selected_branch_patterns']
      if 'selected_branch_patterns' in hmpps_template
      else []
    }
  )
  hmpps_template.update(
    {
      'source_template_repo': hmpps_template['source_template_repo']
      if 'source_template_repo' in hmpps_template
      else None
    }
  )
  hmpps_template.update(
    {
      'protected_branches_only': hmpps_template['protected_branches_only']
      if 'protected_branches_only' in hmpps_template
      else None
    }
  )
  hmpps_template.update(
    {
      'prevent_self_review': hmpps_template['prevent_self_review']
      if 'prevent_self_review' in hmpps_template
      else None
    }
  )

  # Clean up field not used in post to SC
  del hmpps_template['__tfmeta']

  # Check for existing template in SC and update same ID if so.
  try:
    # If there are any hmpps_templates in the existing SC data
    if sc_namespace_attributes.get('hmpps_template', {}):
      # Find the template SC ID that matches
      template_id = list(
        filter(
          lambda template: template['tf_path'] == hmpps_template['__tfmeta']['path'],
          sc_namespace_attributes.get('hmpps_terraform', {}),
        )
      )[0]['id']
      hmpps_template.update({'id': template_id})
  except (IndexError, KeyError):
    pass
  return hmpps_template


def process_repo(component, lock, services):
  global namespaces
  sc = services.sc
  for environment in component.get('envs'):
    namespace = environment.get('namespace', {})
    log_debug(f'Processing environment/namepace: {environment.get("name")}:{namespace}')
    if namespace not in namespaces:
      # Add namespace to list of namespaces being done.
      namespaces.append(namespace)
    else:
      # Skip this namespace as it's already processed.
      log_debug(f'skipping {namespace} namespace - already been processed')
      continue

    namespace_id = None
    if sc_namespace_data := sc.get_record(sc.namespaces_get, 'name', namespace):
      log_debug(f'Namespace data: {sc_namespace_data}')
      namespace_id = sc_namespace_data.get('documentId')
      log_debug(f'Namespace ID: {namespace_id}')

    data = {
      'name': namespace,
      'rds_instance': [],
      'elasticache_cluster': [],
      'hmpps_template': [],
      'pingdom_check': [],
    }

    resources_dir = f'{TEMP_DIR}/namespaces/live.cloud-platform.service.justice.gov.uk/{namespace}/resources'

    if os.path.isdir(resources_dir):
      # tfparse is not thread-safe!
      with lock:
        log_debug(f'Thread locked for tfparse: {resources_dir}')
        parsed = load_from_path(resources_dir)
      for m in parsed['module']:
        # Get terraform module version
        tf_mod_version = str()
        try:
          regex = r'(?<=[\\?]ref=)[0-9]+(\.[0-9])?(\.[0-9])?$'
          tf_mod_version = re.search(regex, m['source'])[0]
        except TypeError:
          pass

        # Check if the namespace uses the cloud-platform-terraform-hmpps-template
        if 'cloud-platform-terraform-hmpps-template' in m['source']:
          h_sc_fields = hmpps_template_fields = [
            'tf_label',
            'tf_line_start',
            'tf_line_end',
            'tf_path',
            'tf_filename',
            'application',
            'application_insights_instance',
            'environment_name',
            'github_repo',
            'github_team_name',
            'namespace',
            'reviewer_teams',
            'selected_branch_patterns',
            'source_template_repo',
            'protected_branches_only',
            'is_production',
            'tf_mod_version',
            'prevent_self_review',
          ]
          # Process fields
          hmpps_template = {
            key: (
              m['__tfmeta'][key.split('tf_')[1]]
              if key.startswith('tf_') and key.split('tf_')[1] in m['__tfmeta']
              else m.get(
                key,
                [] if key in ['reviewer_teams', 'selected_branch_patterns'] else None,
              )
            )
            for key in h_sc_fields
          }
          hmpps_template['namespace'] = locals().get('namespace')
          hmpps_template['tf_mod_version'] = tf_mod_version
          if 'hmpps_template' in data:
            data['hmpps_template'].append(hmpps_template)

        # Look for RDS instances.
        if 'cloud-platform-terraform-rds-instance' in m['source']:
          rds_instance = m
          rd_sc_fields = [
            'tf_label',
            'db_instance_class',
            'db_engine_version',
            'rds_family',
            'is_production',
            'namespace',
            'environment_name',
            'application',
            'tf_filename',
            'tf_path',
            'tf_line_start',
            'tf_line_end',
            'db_max_allocated_storage',
            'infrastructure_support',
            'business_unit',
            'team_name',
            'tf_mod_version',
            'performance_insights_enabled',
            'allow_major_version_upgrade',
            'allow_minor_version_upgrade',
            'deletion_protection',
            'maintenance_window',
            'backup_window',
            'db_parameter',
          ]
          rds_instance = {
            key: (
              m['__tfmeta'][key.split('tf_')[1]]
              if key.startswith('tf_') and key.split('tf_')[1] in m['__tfmeta']
              else str(m[key])
              if key == 'db_max_allocated_storage' and isinstance(m.get(key), int)
              else tf_mod_version
              if key == 'tf_mod_version'
              else m.get(key)
            )
            for key in rd_sc_fields
          }
          data['rds_instance'].append(rds_instance)

        # Look for elasticache instances.
        if 'cloud-platform-terraform-elasticache-cluster' in m['source']:
          ec_sc_fields = [
            'application',
            'business_unit',
            'engine_version',
            'environment_name',
            'infrastructure_support',
            'is_production',
            'namespace',
            'node_type',
            'number_cache_clusters',
            'parameter_group_name',
            'team_name',
            'tf_label',
            'tf_filename',
            'tf_path',
            'tf_line_end',
            'tf_line_start',
            'tf_mod_version',
          ]
          elasticache_cluster = m
          # Process fields
          elasticache_cluster = {
            key: (
              m['__tfmeta'][key.split('tf_')[1]]
              if key.startswith('tf_') and key.split('tf_')[1] in m['__tfmeta']
              else m['parameter_group_name']['__name__']
              if key == 'parameter_group_name'
              and isinstance(m.get('parameter_group_name'), dict)
              else tf_mod_version
              if key == 'tf_mod_version'
              else m.get(key)
            )
            for key in ec_sc_fields
          }
          data['elasticache_cluster'].append(elasticache_cluster)

      if 'pingdom_check' in parsed.keys():
        p_sc_fields = [
          'tf_label',
          'tf_filename',
          'tf_path',
          'tf_line_start',
          'tf_line_end',
          'type',
          'name',
          'host',
          'url',
          'probefilters',
          'encryption',
          'resolution',
          'notifywhenbackup',
          'sendnotificationwhendown',
          'notifyagainevery',
          'port',
          'integrationids',
        ]

        for r in parsed['pingdom_check']:
          if 'http' in r['type'] and '__tfmeta' in r.keys():
            pingdom_check = {
              key: (
                r['__tfmeta'][key.split('tf_')[1]]
                if key.startswith('tf_') and key.split('tf_')[1] in r['__tfmeta']
                else r.get(key)
              )
              for key in p_sc_fields
            }
            # Append the processed entry to the list
            data['pingdom_check'].append(pingdom_check)

    # update or add the namespace record
    log_debug(f'Namespace id:{namespace_id}, data: {data}')
    if namespace_id:
      sc.update('namespaces', namespace_id, data)
    else:
      sc.add('namespaces', data)

  return True


def process_components(components, services):
  log_info(f'Processing batch of {len(components)} components...')
  lock = threading.Lock()
  component_count = 1
  t_repo = threading.local()
  for component in components:
    t_repo = threading.Thread(
      target=process_repo, args=(component, lock, services), daemon=True
    )

    # Apply limit on total active threads
    while threading.active_count() > (MAX_THREADS - 1):
      log_debug(f'Active Threads={threading.active_count()}, Max Threads={MAX_THREADS}')
      sleep(10)

    t_repo.start()
    component_name = component.get('name')
    log_info(
      f'Started thread for {component_name} ({component_count}/{len(components)})'
    )
    component_count += 1

  t_repo.join()
  log_info('Completed processing components')


def main():
  slack_params = {
    'token': os.getenv('SLACK_BOT_TOKEN'),
    'notify_channel': os.getenv('SLACK_NOTIFY_CHANNEL', ''),
    'alert_channel': os.getenv('SLACK_ALERT_CHANNEL', ''),
  }

  # service catalogue parameters
  sc_params = {
    'url': os.getenv('SERVICE_CATALOGUE_API_ENDPOINT'),
    'key': os.getenv('SERVICE_CATALOGUE_API_KEY'),
    'filter': os.getenv('SC_FILTER', ''),
  }

  job.name = 'hmpps-terraform-discovery'
  services = Services(sc_params, slack_params)
  sc = services.sc
  slack = services.slack
  if not os.path.isdir(TEMP_DIR):
    try:
      cp_envs_repo = Repo.clone_from(
        'https://github.com/ministryofjustice/cloud-platform-environments.git', TEMP_DIR
      )
    except Exception as e:
      slack.alert(
        f'*Terraform Discovery failed*: Unable to clone cloud-platform-environments repo: {e}'
      )
      log_error(f'Unable to clone cloud-platform-environments repo: {e}')
      sc.update_scheduled_job('Failed')
      raise SystemExit()
  else:
    try:
      cp_envs_repo = Repo(TEMP_DIR)
      origin = cp_envs_repo.remotes.origin
      origin.pull()
    except Exception as e:
      slack.alert(
        f'*Terraform Discovery failed*: Unable to pull latest version of cloud-platform-environments repo: {e}'
      )
      log_error(
        f'Unable to pull latest version of cloud-platform-environments repo: {e}'
      )
      sc.update_scheduled_job('Failed')
      raise SystemExit()

  sc_data = sc.get_all_records(sc.components_get)
  if sc_data:
    process_components(sc_data, services)

  if job.error_messages:
    sc.update_scheduled_job('Errors')
    log_info('Terraform discovery job completed  with errors.')
  else:
    sc.update_scheduled_job('Succeeded')
    log_info('Terraform discovery job completed successfully.')


if __name__ == '__main__':
  main()
